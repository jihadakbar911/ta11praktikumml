{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5c9974a",
   "metadata": {},
   "source": [
    "---\n",
    "## **1. Setup & Load Data**\n",
    "### 1.1 Mount Google Drive & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b426f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive untuk akses dataset\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da745893",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import semua library yang diperlukan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "\n",
    "# Deep Learning - Keras/TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Evaluasi\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "# Pengaturan tampilan\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ae31d7",
   "metadata": {},
   "source": [
    "### 1.2 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9541cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sesuaikan path dengan lokasi file di Google Drive Anda\n",
    "# Contoh: '/content/drive/MyDrive/Tugas/WA_Fn-UseC_-Telco-Customer-Churn.csv'\n",
    "\n",
    "file_path = '/content/drive/MyDrive/WA_Fn-UseC_-Telco-Customer-Churn.csv'  # SESUAIKAN PATH INI!\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Dataset berhasil dimuat!\")\n",
    "print(f\"Jumlah baris: {df.shape[0]}\")\n",
    "print(f\"Jumlah kolom: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b43f33",
   "metadata": {},
   "source": [
    "---\n",
    "## **2. Exploratory Data Analysis (EDA) Singkat**\n",
    "### 2.1 Overview Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb90834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tampilkan 5 baris pertama\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139b2936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informasi struktur dataset\n",
    "print(\"=\" * 60)\n",
    "print(\"INFORMASI DATASET\")\n",
    "print(\"=\" * 60)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc97e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik deskriptif\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7bad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek nilai unik setiap kolom\n",
    "print(\"=\" * 60)\n",
    "print(\"NILAI UNIK SETIAP KOLOM\")\n",
    "print(\"=\" * 60)\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71116e1",
   "metadata": {},
   "source": [
    "### 2.2 Cek Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a89949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek missing values\n",
    "print(\"=\" * 60)\n",
    "print(\"MISSING VALUES\")\n",
    "print(\"=\" * 60)\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Values': missing_values,\n",
    "    'Percentage (%)': missing_percentage\n",
    "})\n",
    "print(missing_df[missing_df['Missing Values'] > 0])\n",
    "\n",
    "if missing_df['Missing Values'].sum() == 0:\n",
    "    print(\"\\n‚úì Tidak ada missing values yang terdeteksi (null/NaN)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c54345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek nilai kosong atau spasi pada kolom object\n",
    "print(\"=\" * 60)\n",
    "print(\"CEK NILAI KOSONG/SPASI PADA KOLOM KATEGORIK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    empty_count = (df[col].str.strip() == '').sum()\n",
    "    if empty_count > 0:\n",
    "        print(f\"{col}: {empty_count} nilai kosong/spasi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e785c702",
   "metadata": {},
   "source": [
    "### 2.3 Distribusi Target (Churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db543c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribusi target variable (Churn)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Count plot\n",
    "sns.countplot(data=df, x='Churn', ax=axes[0], palette='coolwarm')\n",
    "axes[0].set_title('Distribusi Customer Churn', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Churn')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Pie chart\n",
    "churn_counts = df['Churn'].value_counts()\n",
    "axes[1].pie(churn_counts, labels=churn_counts.index, autopct='%1.1f%%', \n",
    "            colors=['#3498db', '#e74c3c'], startangle=90, explode=[0, 0.05])\n",
    "axes[1].set_title('Persentase Churn', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nDistribusi Churn:\")\n",
    "print(df['Churn'].value_counts())\n",
    "print(f\"\\nPersentase:\")\n",
    "print(df['Churn'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1d830d",
   "metadata": {},
   "source": [
    "---\n",
    "## **3. Advanced Data Preprocessing (Bobot: 30%)**\n",
    "### 3.1 Handling Missing Values & Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd5e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataframe untuk preprocessing\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Drop kolom customerID (tidak relevan untuk prediksi)\n",
    "df_clean = df_clean.drop('customerID', axis=1)\n",
    "\n",
    "print(\"‚úì Kolom 'customerID' telah dihapus\")\n",
    "print(f\"Jumlah kolom sekarang: {df_clean.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a4290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi TotalCharges ke numerik (ada nilai spasi yang perlu di-handle)\n",
    "# TotalCharges seharusnya numerik tapi mungkin ada nilai kosong/spasi\n",
    "\n",
    "# Cek tipe data TotalCharges\n",
    "print(f\"Tipe data TotalCharges: {df_clean['TotalCharges'].dtype}\")\n",
    "\n",
    "# Konversi ke numerik, error akan jadi NaN\n",
    "df_clean['TotalCharges'] = pd.to_numeric(df_clean['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Cek missing values setelah konversi\n",
    "print(f\"\\nMissing values di TotalCharges setelah konversi: {df_clean['TotalCharges'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2e7f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDLING MISSING VALUES - Imputasi\n",
    "# Untuk TotalCharges yang missing, bisa diisi dengan median atau nilai berdasarkan tenure\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"HANDLING MISSING VALUES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Cek baris dengan TotalCharges NaN\n",
    "missing_total_charges = df_clean[df_clean['TotalCharges'].isnull()]\n",
    "print(f\"\\nBaris dengan TotalCharges kosong:\")\n",
    "print(missing_total_charges[['tenure', 'MonthlyCharges', 'TotalCharges']])\n",
    "\n",
    "# Insight: Customer dengan tenure = 0 memiliki TotalCharges kosong\n",
    "# Imputasi: TotalCharges = tenure * MonthlyCharges (jika tenure=0, maka TotalCharges=0)\n",
    "# Atau gunakan median\n",
    "\n",
    "# Metode 1: Imputasi dengan MonthlyCharges (karena tenure=0, TotalCharges = MonthlyCharges)\n",
    "df_clean['TotalCharges'].fillna(df_clean['MonthlyCharges'], inplace=True)\n",
    "\n",
    "# Verifikasi tidak ada lagi missing values\n",
    "print(f\"\\n‚úì Missing values setelah imputasi: {df_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc9c01",
   "metadata": {},
   "source": [
    "### 3.2 Encoding - Label Encoder untuk Target & One-Hot Encoding untuk Fitur Kategori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfad264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifikasi kolom numerik dan kategorik\n",
    "print(\"=\" * 60)\n",
    "print(\"IDENTIFIKASI TIPE KOLOM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "numerical_cols = df_clean.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = df_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Hapus target dari categorical (akan di-encode terpisah)\n",
    "categorical_cols.remove('Churn')\n",
    "\n",
    "print(f\"\\nKolom Numerik ({len(numerical_cols)}): {numerical_cols}\")\n",
    "print(f\"\\nKolom Kategorik ({len(categorical_cols)}): {categorical_cols}\")\n",
    "print(f\"\\nTarget: Churn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d3f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL ENCODER untuk target biner (Churn: Yes/No -> 1/0)\n",
    "print(\"=\" * 60)\n",
    "print(\"LABEL ENCODING - TARGET (Churn)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_clean['Churn'] = label_encoder.fit_transform(df_clean['Churn'])\n",
    "\n",
    "print(f\"Mapping: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}\")\n",
    "print(f\"\\nDistribusi Churn setelah encoding:\")\n",
    "print(df_clean['Churn'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94d1127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE-HOT ENCODING untuk fitur kategori nominal\n",
    "print(\"=\" * 60)\n",
    "print(\"ONE-HOT ENCODING - FITUR KATEGORIK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Tampilkan nilai unik setiap kolom kategorik sebelum encoding\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}: {df_clean[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa4b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lakukan One-Hot Encoding dengan pd.get_dummies\n",
    "# drop_first=True untuk menghindari multicollinearity\n",
    "\n",
    "df_encoded = pd.get_dummies(df_clean, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "print(f\"\\nJumlah kolom sebelum encoding: {df_clean.shape[1]}\")\n",
    "print(f\"Jumlah kolom setelah One-Hot Encoding: {df_encoded.shape[1]}\")\n",
    "print(f\"\\nKolom baru setelah encoding:\")\n",
    "print(df_encoded.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f1f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tampilkan sample data setelah encoding\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283d089a",
   "metadata": {},
   "source": [
    "### 3.3 Feature Scaling (WAJIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b123448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pisahkan fitur (X) dan target (y)\n",
    "X = df_encoded.drop('Churn', axis=1)\n",
    "y = df_encoded['Churn']\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "print(f\"\\nJumlah fitur input: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134a8b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE SCALING menggunakan StandardScaler\n",
    "# StandardScaler: mean=0, std=1 (lebih baik untuk ANN)\n",
    "# MinMaxScaler: range [0,1]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURE SCALING - StandardScaler\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit dan transform data\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Konversi kembali ke DataFrame untuk visualisasi\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "print(\"\\nStatistik sebelum scaling:\")\n",
    "print(X[['tenure', 'MonthlyCharges', 'TotalCharges']].describe())\n",
    "\n",
    "print(\"\\nStatistik setelah scaling:\")\n",
    "print(X_scaled_df[['tenure', 'MonthlyCharges', 'TotalCharges']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27829095",
   "metadata": {},
   "source": [
    "### 3.4 Split Data: Training, Validation, dan Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce89e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DATA\n",
    "# Pertama: Split menjadi Train (80%) dan Test (20%)\n",
    "# Validation set akan dibuat otomatis saat training (validation_split)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SPLIT DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y  # Menjaga proporsi kelas\n",
    ")\n",
    "\n",
    "print(f\"\\nUkuran Training Set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Ukuran Test Set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nDistribusi Churn di Training Set:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(f\"\\nDistribusi Churn di Test Set:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83a64cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi ke numpy array dan pastikan tipe data yang benar\n",
    "X_train = np.array(X_train).astype('float32')\n",
    "X_test = np.array(X_test).astype('float32')\n",
    "y_train = np.array(y_train).astype('float32')\n",
    "y_test = np.array(y_test).astype('float32')\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce06a91f",
   "metadata": {},
   "source": [
    "---\n",
    "## **4. Pembangunan Model (Model Building) (Bobot: 20%)**\n",
    "### 4.1 Arsitektur Model ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69337261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisi jumlah fitur input\n",
    "input_dim = X_train.shape[1]\n",
    "print(f\"Jumlah fitur input (input_dim): {input_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2d3f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEMBANGUN MODEL ANN dengan Keras Sequential\n",
    "print(\"=\" * 60)\n",
    "print(\"ARSITEKTUR MODEL ANN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Inisialisasi model Sequential\n",
    "model = Sequential(name='ANN_Customer_Churn')\n",
    "\n",
    "# INPUT LAYER + HIDDEN LAYER 1\n",
    "model.add(Dense(\n",
    "    units=64,                    # Jumlah neuron\n",
    "    activation='relu',           # Fungsi aktivasi ReLU\n",
    "    input_dim=input_dim,         # Dimensi input\n",
    "    name='hidden_layer_1'\n",
    "))\n",
    "model.add(BatchNormalization())  # Batch Normalization untuk stabilitas\n",
    "model.add(Dropout(0.3))          # Dropout untuk mencegah overfitting\n",
    "\n",
    "# HIDDEN LAYER 2\n",
    "model.add(Dense(\n",
    "    units=32,                    # Jumlah neuron\n",
    "    activation='relu',           # Fungsi aktivasi ReLU\n",
    "    name='hidden_layer_2'\n",
    "))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# HIDDEN LAYER 3 (Tambahan untuk performa lebih baik)\n",
    "model.add(Dense(\n",
    "    units=16,                    # Jumlah neuron\n",
    "    activation='relu',           # Fungsi aktivasi ReLU\n",
    "    name='hidden_layer_3'\n",
    "))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# OUTPUT LAYER\n",
    "# Klasifikasi Biner: 1 neuron dengan aktivasi Sigmoid\n",
    "model.add(Dense(\n",
    "    units=1,                     # 1 output untuk binary classification\n",
    "    activation='sigmoid',        # Sigmoid untuk probabilitas 0-1\n",
    "    name='output_layer'\n",
    "))\n",
    "\n",
    "print(\"\\n‚úì Model berhasil dibuat!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b564ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tampilkan ringkasan arsitektur model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57214f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi arsitektur model (opsional)\n",
    "try:\n",
    "    from tensorflow.keras.utils import plot_model\n",
    "    plot_model(model, show_shapes=True, show_layer_names=True, \n",
    "               to_file='model_architecture.png', dpi=100)\n",
    "    from IPython.display import Image\n",
    "    display(Image('model_architecture.png'))\n",
    "except:\n",
    "    print(\"Visualisasi model tidak tersedia (memerlukan graphviz)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a3ed15",
   "metadata": {},
   "source": [
    "---\n",
    "## **5. Kompilasi & Training (Bobot: 20%)**\n",
    "### 5.1 Kompilasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILE MODEL\n",
    "print(\"=\" * 60)\n",
    "print(\"KOMPILASI MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',                          # Optimizer Adam (adaptive learning rate)\n",
    "    loss='binary_crossentropy',                # Loss function untuk binary classification\n",
    "    metrics=['accuracy']                       # Metrik evaluasi\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Model berhasil dikompilasi!\")\n",
    "print(f\"   - Optimizer: Adam\")\n",
    "print(f\"   - Loss Function: Binary Crossentropy\")\n",
    "print(f\"   - Metrics: Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b99a44",
   "metadata": {},
   "source": [
    "### 5.2 Training Model\n",
    "\n",
    "#### ‚ö†Ô∏è Penanganan Data Imbalance dengan class_weight\n",
    "Pada dataset churn, jumlah pelanggan yang churn biasanya jauh lebih sedikit dibanding yang tidak churn (data imbalance).\n",
    "Agar model lebih sensitif terhadap kelas minoritas (churn), kita bisa menggunakan parameter `class_weight` pada `model.fit`.\n",
    "Dengan ini, model akan memberi bobot lebih besar pada kesalahan prediksi churn, sehingga prediksi churn menjadi lebih baik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8c2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisi Early Stopping Callback untuk mencegah overfitting\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',      # Monitor validation loss\n",
    "    patience=10,             # Berhenti jika tidak ada improvement dalam 10 epoch\n",
    "    restore_best_weights=True,  # Kembalikan ke weights terbaik\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"‚úì Early Stopping callback telah dikonfigurasi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0785a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING MODEL dengan class_weight untuk mengatasi imbalance\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Hyperparameter training\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.2  # 20% dari training data untuk validation\n",
    "\n",
    "# Hitung class_weight secara otomatis\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "print(f'Class weight: {class_weight_dict}')\n",
    "\n",
    "print(f\"\\nHyperparameter:\")\n",
    "print(f\"   - Epochs: {EPOCHS}\")\n",
    "print(f\"   - Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   - Validation Split: {VALIDATION_SPLIT}\")\n",
    "print(\"\\nMemulai training...\\n\")\n",
    "\n",
    "# Training dan simpan history\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,  # Otomatis membuat validation set\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1,\n",
    "    class_weight=class_weight_dict  # <--- inilah kuncinya\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úì Training selesai!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef49c50",
   "metadata": {},
   "source": [
    "---\n",
    "## **6. Visualisasi Grafik (Loss/Accuracy)**\n",
    "### 6.1 Plot Loss dan Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edc91b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ekstrak data dari history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs_range = range(1, len(train_loss) + 1)\n",
    "\n",
    "print(f\"Jumlah epoch yang dijalankan: {len(train_loss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a0daee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALISASI LOSS DAN ACCURACY\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Loss (Train vs Validation)\n",
    "axes[0].plot(epochs_range, train_loss, 'b-', label='Training Loss', linewidth=2)\n",
    "axes[0].plot(epochs_range, val_loss, 'r-', label='Validation Loss', linewidth=2)\n",
    "axes[0].set_title('Model Loss (Train vs Validation)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].legend(loc='upper right', fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xlim([1, len(train_loss)])\n",
    "\n",
    "# Plot 2: Accuracy (Train vs Validation)\n",
    "axes[1].plot(epochs_range, train_acc, 'b-', label='Training Accuracy', linewidth=2)\n",
    "axes[1].plot(epochs_range, val_acc, 'r-', label='Validation Accuracy', linewidth=2)\n",
    "axes[1].set_title('Model Accuracy (Train vs Validation)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].legend(loc='lower right', fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xlim([1, len(train_acc)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Grafik disimpan sebagai 'training_history.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b30e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALISIS OVERFITTING\n",
    "print(\"=\" * 60)\n",
    "print(\"ANALISIS OVERFITTING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Cek nilai akhir\n",
    "final_train_loss = train_loss[-1]\n",
    "final_val_loss = val_loss[-1]\n",
    "final_train_acc = train_acc[-1]\n",
    "final_val_acc = val_acc[-1]\n",
    "\n",
    "print(f\"\\nNilai Akhir Training:\")\n",
    "print(f\"   - Training Loss: {final_train_loss:.4f}\")\n",
    "print(f\"   - Validation Loss: {final_val_loss:.4f}\")\n",
    "print(f\"   - Training Accuracy: {final_train_acc:.4f}\")\n",
    "print(f\"   - Validation Accuracy: {final_val_acc:.4f}\")\n",
    "\n",
    "# Analisis gap\n",
    "loss_gap = final_val_loss - final_train_loss\n",
    "acc_gap = final_train_acc - final_val_acc\n",
    "\n",
    "print(f\"\\nAnalisis Gap:\")\n",
    "print(f\"   - Gap Loss (Val - Train): {loss_gap:.4f}\")\n",
    "print(f\"   - Gap Accuracy (Train - Val): {acc_gap:.4f}\")\n",
    "\n",
    "# Interpretasi\n",
    "print(f\"\\nüìä Interpretasi:\")\n",
    "if loss_gap > 0.1:\n",
    "    print(\"   ‚ö†Ô∏è Terdapat indikasi OVERFITTING (validation loss > training loss)\")\n",
    "    print(\"   ‚Üí Model mungkin terlalu 'menghafal' data training\")\n",
    "else:\n",
    "    print(\"   ‚úì Model terlihat BAIK (gap loss kecil)\")\n",
    "    print(\"   ‚Üí Model memiliki generalisasi yang baik\")\n",
    "\n",
    "if acc_gap > 0.05:\n",
    "    print(\"   ‚ö†Ô∏è Gap accuracy cukup besar, pertimbangkan regularisasi tambahan\")\n",
    "else:\n",
    "    print(\"   ‚úì Gap accuracy dalam batas wajar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad15d72",
   "metadata": {},
   "source": [
    "---\n",
    "## **7. Evaluasi Akhir (Bobot: 30%)**\n",
    "### 7.1 Prediksi pada Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5428ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi model pada Test Set\n",
    "print(\"=\" * 60)\n",
    "print(\"EVALUASI PADA TEST SET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Evaluasi menggunakan model.evaluate()\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"\\nHasil Evaluasi Test Set:\")\n",
    "print(f\"   - Test Loss: {test_loss:.4f}\")\n",
    "print(f\"   - Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaf107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prediksi pada Test Set + threshold optimal berbasis F1 agar churn tidak terlewat\n",
    "y_pred_proba = model.predict(X_test)  # Probabilitas\n",
    "\n",
    "# Cari threshold terbaik dengan grid sederhana\n",
    "threshold_candidates = np.linspace(0.2, 0.6, 9)\n",
    "threshold_scores = []\n",
    "for th in threshold_candidates:\n",
    "    preds_tmp = (y_pred_proba > th).astype(int).flatten()\n",
    "    score = f1_score(y_test, preds_tmp)\n",
    "    threshold_scores.append((th, score))\n",
    "\n",
    "best_threshold, best_f1 = max(threshold_scores, key=lambda x: x[1])\n",
    "\n",
    "print(f\"Kandidat threshold: {np.round(threshold_candidates, 2)}\")\n",
    "print(f\"Threshold terbaik (F1): {best_threshold:.2f} | F1: {best_f1:.4f}\")\n",
    "\n",
    "# Gunakan threshold terbaik\n",
    "y_pred = (y_pred_proba > best_threshold).astype(int).flatten()\n",
    "\n",
    "print(f\"Shape y_pred_proba: {y_pred_proba.shape}\")\n",
    "print(f\"Shape y_pred: {y_pred.shape}\")\n",
    "print(f\"\\nSample prediksi (5 pertama):\")\n",
    "print(f\"Probabilitas: {y_pred_proba[:5].flatten()}\")\n",
    "print(f\"Prediksi (threshold {best_threshold:.2f}): {y_pred[:5]}\")\n",
    "print(f\"Aktual: {y_test[:5].astype(int)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67649e9a",
   "metadata": {},
   "source": [
    "### 7.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef03b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFUSION MATRIX\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualisasi Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Churn (0)', 'Churn (1)'],\n",
    "            yticklabels=['No Churn (0)', 'Churn (1)'],\n",
    "            annot_kws={'size': 14})\n",
    "plt.title('Confusion Matrix - Customer Churn Prediction', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"\\n   - True Negative (TN): {cm[0,0]} (Tidak Churn, diprediksi Tidak Churn)\")\n",
    "print(f\"   - False Positive (FP): {cm[0,1]} (Tidak Churn, diprediksi Churn)\")\n",
    "print(f\"   - False Negative (FN): {cm[1,0]} (Churn, diprediksi Tidak Churn)\")\n",
    "print(f\"   - True Positive (TP): {cm[1,1]} (Churn, diprediksi Churn)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723e734",
   "metadata": {},
   "source": [
    "### 7.3 Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fab099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFICATION REPORT\n",
    "print(\"=\" * 60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['No Churn', 'Churn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51486686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung metrik tambahan\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RINGKASAN METRIK EVALUASI\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n   Accuracy    : {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"   Precision   : {precision:.4f} ({precision*100:.2f}%)\")\n",
    "print(f\"   Recall      : {recall:.4f} ({recall*100:.2f}%)\")\n",
    "print(f\"   Specificity : {specificity:.4f} ({specificity*100:.2f}%)\")\n",
    "print(f\"   F1-Score    : {f1:.4f} ({f1*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6647ca3e",
   "metadata": {},
   "source": [
    "### 7.4 ROC Curve dan AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c318b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC CURVE dan AUC SCORE\n",
    "print(\"=\" * 60)\n",
    "print(\"ROC CURVE & AUC SCORE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Hitung ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (Sensitivity/Recall)', fontsize=12)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAUC Score: {roc_auc:.4f}\")\n",
    "print(f\"\\nüìä Interpretasi AUC:\")\n",
    "if roc_auc >= 0.9:\n",
    "    print(\"   ‚úì Excellent (AUC ‚â• 0.9)\")\n",
    "elif roc_auc >= 0.8:\n",
    "    print(\"   ‚úì Good (0.8 ‚â§ AUC < 0.9)\")\n",
    "elif roc_auc >= 0.7:\n",
    "    print(\"   ‚Üí Fair (0.7 ‚â§ AUC < 0.8)\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Poor (AUC < 0.7)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a832a",
   "metadata": {},
   "source": [
    "---\n",
    "## **8. Kesimpulan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa393532",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RINGKASAN HASIL\n",
    "print(\"=\" * 70)\n",
    "print(\"                    RINGKASAN HASIL MODEL ANN\")\n",
    "print(\"                  PREDIKSI CUSTOMER CHURN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n Dataset: Telco Customer Churn\")\n",
    "print(f\"   - Total samples: {len(df)}\")\n",
    "print(f\"   - Total features (setelah encoding): {input_dim}\")\n",
    "\n",
    "print(f\"\\n Arsitektur Model:\")\n",
    "print(f\"   - Input Layer: {input_dim} features\")\n",
    "print(f\"   - Hidden Layer 1: 64 neurons (ReLU) + BatchNorm + Dropout(0.3)\")\n",
    "print(f\"   - Hidden Layer 2: 32 neurons (ReLU) + BatchNorm + Dropout(0.3)\")\n",
    "print(f\"   - Hidden Layer 3: 16 neurons (ReLU) + Dropout(0.2)\")\n",
    "print(f\"   - Output Layer: 1 neuron (Sigmoid)\")\n",
    "\n",
    "print(f\"\\n Training Configuration:\")\n",
    "print(f\"   - Optimizer: Adam\")\n",
    "print(f\"   - Loss Function: Binary Crossentropy\")\n",
    "print(f\"   - Epochs: {len(train_loss)} (dengan Early Stopping)\")\n",
    "print(f\"   - Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   - Threshold Prediksi (F1): {globals().get('best_threshold', 0.5):.2f}\")\n",
    "\n",
    "print(f\"\\n Hasil Evaluasi (Test Set):\")\n",
    "print(f\"   - Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"   - Precision: {precision*100:.2f}%\")\n",
    "print(f\"   - Recall: {recall*100:.2f}%\")\n",
    "print(f\"   - F1-Score: {f1*100:.2f}%\")\n",
    "print(f\"   - AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "print(f\"\\n Analisis Overfitting:\")\n",
    "print(f\"   - Training Loss: {final_train_loss:.4f}\")\n",
    "print(f\"   - Validation Loss: {final_val_loss:.4f}\")\n",
    "print(f\"   - Gap: {loss_gap:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"                         END OF NOTEBOOK\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134e7279",
   "metadata": {},
   "source": [
    "---\n",
    "## **9. Simpan Model (Opsional)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simpan model untuk penggunaan selanjutnya\n",
    "model.save('customer_churn_ann_model.h5')\n",
    "print(\" Model disimpan sebagai 'customer_churn_ann_model.h5'\")\n",
    "\n",
    "# Simpan scaler untuk deployment\n",
    "import joblib\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "print(\" Scaler disimpan sebagai 'scaler.pkl'\")\n",
    "\n",
    "# Simpan nama kolom fitur untuk deployment\n",
    "import json\n",
    "feature_columns = X.columns.tolist()\n",
    "with open('feature_columns.json', 'w') as f:\n",
    "    json.dump(feature_columns, f)\n",
    "print(\" Feature columns disimpan sebagai 'feature_columns.json'\")\n",
    "\n",
    "# Simpan kategori unik untuk setiap kolom kategorik (untuk dropdown di Streamlit)\n",
    "categorical_options = {}\n",
    "for col in categorical_cols:\n",
    "    categorical_options[col] = df[col].unique().tolist()\n",
    "\n",
    "with open('categorical_options.json', 'w') as f:\n",
    "    json.dump(categorical_options, f)\n",
    "print(\" Categorical options disimpan sebagai 'categorical_options.json'\")\n",
    "\n",
    "# Simpan threshold terbaik (berbasis F1) untuk deployment\n",
    "best_threshold_to_save = float(globals().get('best_threshold', 0.5))\n",
    "with open('threshold.json', 'w') as f:\n",
    "    json.dump({'threshold': best_threshold_to_save}, f)\n",
    "print(f\" Threshold terbaik ({best_threshold_to_save:.2f}) disimpan sebagai 'threshold.json'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SEMUA FILE UNTUK DEPLOYMENT SUDAH TERSIMPAN!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nFile yang dihasilkan:\")\n",
    "print(\"1. customer_churn_ann_model.h5 - Model ANN\")\n",
    "print(\"2. scaler.pkl - StandardScaler\")\n",
    "print(\"3. feature_columns.json - Nama kolom fitur\")\n",
    "print(\"4. categorical_options.json - Opsi untuk input kategorik\")\n",
    "print(\"5. threshold.json - Ambang probabilitas terbaik (F1)\")\n",
    "\n",
    "# Download file (untuk Google Colab)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DOWNLOAD FILES UNTUK DEPLOYMENT\")\n",
    "print(\"=\"*60)\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print(\"\\nMengunduh file...\")\n",
    "    files.download('customer_churn_ann_model.h5')\n",
    "    files.download('scaler.pkl')\n",
    "    files.download('feature_columns.json')\n",
    "    files.download('categorical_options.json')\n",
    "    files.download('threshold.json')\n",
    "    print(\" Semua file berhasil diunduh!\")\n",
    "except:\n",
    "    print(\"\\nJika di Google Colab, gunakan kode berikut untuk download:\")\n",
    "    print(\"from google.colab import files\")\n",
    "    print(\"files.download('customer_churn_ann_model.h5')\")\n",
    "    print(\"files.download('scaler.pkl')\")\n",
    "    print(\"files.download('feature_columns.json')\")\n",
    "    print(\"files.download('categorical_options.json')\")\n",
    "    print(\"files.download('threshold.json')\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}